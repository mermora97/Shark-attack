{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "import pandas as pd\n",
    "\n",
    "with open('Input/shark_attack.csv', 'rb') as f:\n",
    "    result = chardet.detect(f.read())  # or readline if the file is large\n",
    "\n",
    "df = pd.read_csv('Input/shark_attack.csv', encoding=result['encoding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 Columns: \n",
      "\n",
      "Case Number, Date, Year, Type, Country, Area, Location, Activity, Name, Sex , Age, Injury, Fatal (Y/N), Time, Species , Investigator or Source, pdf, href formula, href, Case Number.1, Case Number.2, original order, Unnamed: 22, Unnamed: 23\n",
      "\n",
      "Number of samples:  5992\n"
     ]
    }
   ],
   "source": [
    "#Check the columns and number of samples provided by the dataset\n",
    "print(df.shape[1],'Columns: \\n')\n",
    "print(*list(df.columns), sep = \", \")\n",
    "#Number of samples in my data set\n",
    "print('\\nNumber of samples: ',df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>...</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016.09.18.c</td>\n",
       "      <td>18-Sep-16</td>\n",
       "      <td>2016</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Florida</td>\n",
       "      <td>New Smyrna Beach, Volusia County</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Orlando Sentinel, 9/19/2016</td>\n",
       "      <td>2016.09.18.c-NSB.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2016.09.18.c</td>\n",
       "      <td>2016.09.18.c</td>\n",
       "      <td>5993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016.09.18.b</td>\n",
       "      <td>18-Sep-16</td>\n",
       "      <td>2016</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Florida</td>\n",
       "      <td>New Smyrna Beach, Volusia County</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Chucky Luciano</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Orlando Sentinel, 9/19/2016</td>\n",
       "      <td>2016.09.18.b-Luciano.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2016.09.18.b</td>\n",
       "      <td>2016.09.18.b</td>\n",
       "      <td>5992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016.09.18.a</td>\n",
       "      <td>18-Sep-16</td>\n",
       "      <td>2016</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Florida</td>\n",
       "      <td>New Smyrna Beach, Volusia County</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Orlando Sentinel, 9/19/2016</td>\n",
       "      <td>2016.09.18.a-NSB.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2016.09.18.a</td>\n",
       "      <td>2016.09.18.a</td>\n",
       "      <td>5991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016.09.17</td>\n",
       "      <td>17-Sep-16</td>\n",
       "      <td>2016</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>Thirteenth Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Rory Angiolella</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Age, 9/18/2016</td>\n",
       "      <td>2016.09.17-Angiolella.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2016.09.17</td>\n",
       "      <td>2016.09.17</td>\n",
       "      <td>5990</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016.09.15</td>\n",
       "      <td>16-Sep-16</td>\n",
       "      <td>2016</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>Bells Beach</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>2 m shark</td>\n",
       "      <td>The Age, 9/16/2016</td>\n",
       "      <td>2016.09.16-BellsBeach.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2016.09.16</td>\n",
       "      <td>2016.09.15</td>\n",
       "      <td>5989</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Case Number       Date  Year        Type    Country      Area  \\\n",
       "0  2016.09.18.c  18-Sep-16  2016  Unprovoked        USA   Florida   \n",
       "1  2016.09.18.b  18-Sep-16  2016  Unprovoked        USA   Florida   \n",
       "2  2016.09.18.a  18-Sep-16  2016  Unprovoked        USA   Florida   \n",
       "3    2016.09.17  17-Sep-16  2016  Unprovoked  AUSTRALIA  Victoria   \n",
       "4    2016.09.15  16-Sep-16  2016  Unprovoked  AUSTRALIA  Victoria   \n",
       "\n",
       "                           Location Activity             Name Sex   ...  \\\n",
       "0  New Smyrna Beach, Volusia County  Surfing             male    M  ...   \n",
       "1  New Smyrna Beach, Volusia County  Surfing   Chucky Luciano    M  ...   \n",
       "2  New Smyrna Beach, Volusia County  Surfing             male    M  ...   \n",
       "3                  Thirteenth Beach  Surfing  Rory Angiolella    M  ...   \n",
       "4                       Bells Beach  Surfing             male    M  ...   \n",
       "\n",
       "    Species        Investigator or Source                        pdf  \\\n",
       "0        NaN  Orlando Sentinel, 9/19/2016       2016.09.18.c-NSB.pdf   \n",
       "1        NaN  Orlando Sentinel, 9/19/2016   2016.09.18.b-Luciano.pdf   \n",
       "2        NaN  Orlando Sentinel, 9/19/2016       2016.09.18.a-NSB.pdf   \n",
       "3        NaN           The Age, 9/18/2016  2016.09.17-Angiolella.pdf   \n",
       "4  2 m shark           The Age, 9/16/2016  2016.09.16-BellsBeach.pdf   \n",
       "\n",
       "                                        href formula  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "3  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "4  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                href Case Number.1  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...  2016.09.18.c   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...  2016.09.18.b   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...  2016.09.18.a   \n",
       "3  http://sharkattackfile.net/spreadsheets/pdf_di...    2016.09.17   \n",
       "4  http://sharkattackfile.net/spreadsheets/pdf_di...    2016.09.16   \n",
       "\n",
       "  Case Number.2 original order Unnamed: 22 Unnamed: 23  \n",
       "0  2016.09.18.c           5993         NaN         NaN  \n",
       "1  2016.09.18.b           5992         NaN         NaN  \n",
       "2  2016.09.18.a           5991         NaN         NaN  \n",
       "3    2016.09.17           5990         NaN         NaN  \n",
       "4    2016.09.15           5989         NaN         NaN  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for null columns or collumns with little information\n",
    "print(df.isnull().sum())\n",
    "#If 80% of the rows are empty we delete the column\n",
    "ncols = [c for c in df.columns if df[c].isnull().sum() > 90 / 100 * df.shape[0]]\n",
    "df = df.drop(ncols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0214\n",
      "0.0336\n",
      "0.0493\n",
      "0.0725\n",
      "ND.0153\n",
      "ND.0152\n",
      "ND.0151\n",
      "ND.0150\n",
      "ND.0149\n",
      "ND.0148\n",
      "ND.1940\n",
      "ND.0139\n",
      "ND.0138\n",
      "ND.0136\n",
      "ND.0135\n",
      "ND.0134\n",
      "ND.0133\n",
      "ND.0132\n",
      "ND.0130\n",
      "ND.0129\n",
      "ND.0127\n",
      "ND.0124\n",
      "ND.0123\n",
      "ND.0122\n",
      "ND.0119\n",
      "ND.0118\n",
      "ND.0116\n",
      "ND.0115\n",
      "nd.0114\n",
      "ND.0113\n",
      "ND.0111\n",
      "ND.0110\n",
      "ND.0109\n",
      "ND.0108\n",
      "ND.0107\n",
      "ND.0106\n",
      "ND.0104\n",
      "ND.0102\n",
      "ND.0100\n",
      "ND.0097\n",
      "ND.0096\n",
      "ND.0095\n",
      "ND.0094\n",
      "ND.0093\n",
      "ND.0091\n",
      "ND.0090\n",
      "ND.0089\n",
      "ND.0088\n",
      "ND.0087\n",
      "ND.0086\n",
      "ND.0085\n",
      "ND.0084\n",
      "ND.0083\n",
      "ND.0082\n",
      "ND.0081\n",
      "ND.0078\n",
      "ND.0076\n",
      "ND.0075\n",
      "ND.0074\n",
      "ND.0073\n",
      "ND.0069\n",
      "ND.0068\n",
      "ND.0066\n",
      "ND.0065\n",
      "ND.0064\n",
      "ND.0063\n",
      "ND.0062\n",
      "ND.0060\n",
      "ND.0059\n",
      "ND.0058\n",
      "ND.0057\n",
      "ND.0056\n",
      "ND.0055\n",
      "ND.0054\n",
      "ND.0053\n",
      "ND.0052\n",
      "ND.0051\n",
      "ND.0049\n",
      "ND.0048\n",
      "ND.0047\n",
      "ND.0046\n",
      "ND.0044\n",
      "ND.0043\n",
      "ND.0042\n",
      "ND.0041\n",
      "ND.0040\n",
      "ND.0039\n",
      "ND.0038\n",
      "ND.0037\n",
      "ND.0036\n",
      "ND.0035\n",
      "ND.0034\n",
      "ND.0033\n",
      "ND.0032\n",
      "ND.0031\n",
      "ND.0030\n",
      "ND.0028\n",
      "ND.0027\n",
      "ND.0026\n",
      "ND.0025\n",
      "ND.0024\n",
      "ND.0023\n",
      "ND.0022\n",
      "ND.0021\n",
      "ND.0020\n",
      "ND.0019\n",
      "ND.0018\n",
      "ND.0017\n",
      "ND.0016\n",
      "ND.0015\n",
      "ND.0014\n",
      "ND.0013\n",
      "ND.0012\n",
      "ND.0011\n",
      "ND.0010\n",
      "ND.0009\n",
      "ND.0008\n",
      "ND.0007\n",
      "ND.0006\n",
      "ND.0005\n",
      "ND.0004\n",
      "ND.0003\n",
      "ND.0002\n",
      "ND.0001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       None\n",
       "1       None\n",
       "2       None\n",
       "3       None\n",
       "4       None\n",
       "        ... \n",
       "5987    None\n",
       "5988    None\n",
       "5989    None\n",
       "5990    None\n",
       "5991    None\n",
       "Name: Case Number, Length: 5992, dtype: object"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clean the Case numbers\n",
    "def printcolumn(e):\n",
    "    print(e)\n",
    "    \n",
    "def checkCNFormat(e):\n",
    "    CN_format = r'\\d{4}\\.\\d{2}\\.\\d{2}\\.?[a-zR]?'\n",
    "    return re.search(CN_format,e) is not None\n",
    "    \n",
    "def printFormatError(e):\n",
    "    if not checkCNFormat(e):\n",
    "        print(e)\n",
    "\n",
    "df['Case Number'] = df['Case Number'].str.replace('[,-]','.')\n",
    "df['Case Number'].apply(printFormatError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boat,Invalid,Provoked,Sea Disaster,Unprovoked\n",
      "[310, 519, 557, 220, 4386]\n",
      "73.19759679572763\n",
      "Most shark attacks (73%) are unprovoked\n"
     ]
    }
   ],
   "source": [
    "#Type\n",
    "def printcolumn(e):\n",
    "    print(e)\n",
    "    \n",
    "def checkTypeFormat(e):\n",
    "    if re.search(r'(?:Unp|P)rovoked',e) is None:\n",
    "        return re.search(r'Invalid|Boat|Sea Disaster',e) is not None\n",
    "    return True\n",
    "def printTypeError(e):\n",
    "    if not checkTypeFormat(e):\n",
    "        print(e)\n",
    "\n",
    "df['Type'] = df['Type'].str.replace('Boating','Boat')\n",
    "#df['Type'].apply(printcolumn)\n",
    "\n",
    "df['Type'].apply(printTypeError)\n",
    "#Type can be Invalid / Boat / Sea Disaster / Provoked / Unprovoked\n",
    "types = [t for t in df.groupby('Type').groups.keys()]\n",
    "\n",
    "print(*types, sep = ',')\n",
    "tcounts = [len(df.groupby(['Type']).groups[t]) for t in types]\n",
    "print(tcounts)\n",
    "print(tcounts[-1]/sum(tcounts)*100)\n",
    "print('Most shark attacks (73%) are unprovoked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEMEN   is the country with most number of shark attacks with  2116\n"
     ]
    }
   ],
   "source": [
    "#Country\n",
    "def checkCountryFormat(e):\n",
    "    return re.search(r'^[A-Z]+\\.?(?:\\s[A-Z]+|\\s|\\(UAE\\)|)+$',e) is not None\n",
    "def printCountryError(e):\n",
    "    if not checkCountryFormat(e):\n",
    "        print(e)\n",
    "\n",
    "def upperCase(e):\n",
    "    return e.upper()\n",
    "\n",
    "df['Country'] = df['Country'].astype(str)\n",
    "df['Country'] = df['Country'].apply(upperCase)\n",
    "df['Country'] = df['Country'].str.replace('&','AND')\n",
    "df['Country'] = df['Country'].str.replace(r'^\\s+','')\n",
    "df['Country'] = df['Country'].str.replace(r'AA','A')\n",
    "\n",
    "#df['Country'].apply(printCountryError)\n",
    "checkCountry = df['Country'].apply(checkCountryFormat)\n",
    "#Set unknown contries to Unknown\n",
    "df['Country'] = df['Country'].where(checkCountry, 'Unknown')\n",
    "#Groupby countries\n",
    "countries = [c for c in df.groupby('Country').groups.keys()]\n",
    "tcounts = [len(df.groupby(['Country']).groups[c]) for c in countries]\n",
    "\n",
    "df_countries = pd.DataFrame({'Country':countries, 'Shark Attacks/country':tcounts})\n",
    "\n",
    "print(df_countries.max().Country, \n",
    "      ' is the country with most number of shark attacks with ',\n",
    "      df_countries.max()['Shark Attacks/country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples with wrong format:  870\n"
     ]
    }
   ],
   "source": [
    "#Limpiar datos\n",
    "\n",
    "import re\n",
    "def checkDateFormat(e):\n",
    "    dformat = '\\d{1,2}-\\w{3}-\\d{2,4}'\n",
    "    return re.search(dformat,e) is not None\n",
    "def printDateErrorFormat(e):\n",
    "    if not checkDateFormat(e):\n",
    "        print(e)\n",
    "\n",
    "#Cleaning the date column dataset\n",
    "df.Date = df.Date.str.replace('Ap-','Apr-')\n",
    "df.Date = df.Date.str.replace(' ','-')\n",
    "df.Date = df.Date.str.replace('-+','-')\n",
    "\n",
    "print ('Number of samples with wrong format: ',(df.Date.apply(checkDateFormat) == False).sum())\n",
    "#df.Date.apply(printDateErrorFormat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples with unknown days:  858\n",
      "Number of samples with unknown months:  1346\n"
     ]
    }
   ],
   "source": [
    "def daySearch(e):\n",
    "    d = re.search(r'\\d{1,2}-\\w{3}',e)\n",
    "    if d is not None:\n",
    "        d = re.search(r'\\d+',d.group(0))\n",
    "        if int(d.group(0)) > 0 and int(d.group(0)) < 32:\n",
    "            return (d.group(0))\n",
    "    return 0\n",
    "\n",
    "def monthSearch(e):\n",
    "    months = ['Jan','Feb','Mar','Apr','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "    d = re.search(r'\\w{3,}-\\d{2,4}',e)\n",
    "    if d is not None:\n",
    "        d = re.search(r'[A-Z]\\w+',d.group(0))\n",
    "        if d is not None and d.group(0)[:3] in months:\n",
    "            return d.group(0)[:3]\n",
    "    return None\n",
    "\n",
    "days = df.Date.apply(daySearch)\n",
    "print('Number of samples with unknown days: ',(days == 0).sum())\n",
    "months = df.Date.apply(monthSearch)\n",
    "print('Number of samples with unknown months: ',(months.isnull()).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples with unknown years:  152\n"
     ]
    }
   ],
   "source": [
    "#Check the year is the same when provided in the date and in the year columns\n",
    "def checkYearFormat(e):\n",
    "    return re.search(r'[12]\\d{3}',str(e)) is not None\n",
    "\n",
    "def printYearError(e):\n",
    "    if not checkYearFormat(e):\n",
    "        print(e)\n",
    "\n",
    "def checkYear(e):\n",
    "    if checkYearFormat(e.Year):\n",
    "        return re.search(str(e.Year)[-2:],e.Date) is not None\n",
    "    return False\n",
    "\n",
    "checkYear = df[['Date', 'Year']].apply(checkYear, axis = 1)\n",
    "years = df.Year.where(checkYear, 0)\n",
    "print('Number of samples with unknown years: ',(years == 0).sum())\n",
    "#df.Year.apply(printYearError)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>Sep</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>Sep</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>Sep</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>Sep</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>Sep</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>Sep</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>Sep</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>07</td>\n",
       "      <td>Sep</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>06</td>\n",
       "      <td>Sep</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>05</td>\n",
       "      <td>Sep</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Day Month  Year\n",
       "0  18   Sep  2016\n",
       "1  18   Sep  2016\n",
       "2  18   Sep  2016\n",
       "3  17   Sep  2016\n",
       "4  16   Sep  2016\n",
       "5  15   Sep  2016\n",
       "6  11   Sep  2016\n",
       "7  07   Sep  2016\n",
       "8  06   Sep  2016\n",
       "9  05   Sep  2016"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_dates = pd.DataFrame({'Day':days, 'Month':months, 'Year':years})\n",
    "display(df_dates.head(10))\n",
    "\n",
    "df_dates.Day = df_dates.Day.astype(int)\n",
    "df_dates.Year = df_dates.Year.astype(int)\n",
    "\n",
    "#How much information rows contain\n",
    "#If 80% of the rows are empty we delete the column\n",
    "nrows = [i for i in df_dates.index\n",
    "         if df_dates.loc[i].Day == 0\n",
    "         or df_dates.loc[i].Month is None\n",
    "         or df_dates.loc[i].Year == 0]\n",
    "\n",
    "df_dates = df_dates.drop(nrows, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Day  Month  Year\n",
       "1    Apr    1934    3\n",
       "            1960    1\n",
       "            1972    2\n",
       "            1987    1\n",
       "            1990    1\n",
       "                   ..\n",
       "31   Oct    2003    3\n",
       "            2004    1\n",
       "            2006    1\n",
       "            2013    1\n",
       "            2014    1\n",
       "Length: 3773, dtype: int64"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_groups = df_dates.groupby(df_dates.columns.tolist(),as_index=False).size()\n",
    "df_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PHILIPPINES  TONGA ADMIRALTY ISLANDS ALGERIA AMERICAN SAMOA ANDAMAN / NICOBAR ISLANDAS ANGOLA ANTIGUA ARGENTINA ARUBA ASIA? ATLANTIC OCEAN AUSTRALIA AZORES BAHAMAS BAHREIN BANGLADESH BARBADOS BAY OF BENGAL BELIZE BERMUDA BRAZIL BRITISH ISLES BRITISH NEW GUINEA BRITISH VIRGIN ISLANDS BRITISH WEST INDIES BURMA Between PORTUGAL & INDIA CANADA CAPE VERDE CARIBBEAN SEA CAYMAN ISLANDS CENTRAL PACIFIC CEYLON (SRI LANKA) CHILE CHINA COLUMBIA COOK ISLANDS COSTA RICA CRETE CROATIA CUBA CURACAO CYPRUS Coast of AFRICA DIEGO GARCIA DJIBOUTI DOMINICAN REPUBLIC ECUADOR EGYPT EGYPT  EGYPT / ISRAEL EL SALVADOR ENGLAND EQUATORIAL GUINEA / CAMEROON FALKLAND ISLANDS FEDERATED STATES OF MICRONESIA FIJI FRANCE FRENCH POLYNESIA Fiji GABON GEORGIA GHANA GRAND CAYMAN GREECE GREENLAND GRENADA GUAM GUATEMALA GUINEA GULF OF ADEN GUYANA HAITI HONDURAS HONG KONG ICELAND INDIA INDIAN OCEAN INDIAN OCEAN? INDONESIA IRAN IRAN / IRAQ IRAQ IRELAND ISRAEL ITALY ITALY / CROATIA JAMAICA JAPAN JAVA JOHNSTON ISLAND KENYA KIRIBATI KOREA KUWAIT LEBANON LIBERIA LIBYA MADAGASCAR MALAYSIA MALDIVE ISLANDS MALTA MARSHALL ISLANDS MARTINIQUE MAURITIUS MAYOTTE MEDITERRANEAN SEA MEDITERRANEAN SEA? MEXICO MEXICO  MICRONESIA MID ATLANTIC OCEAN MID-PACIFC OCEAN MONACO MONTENEGRO MOZAMBIQUE NAMIBIA NETHERLANDS ANTILLES NEVIS NEW BRITAIN NEW CALEDONIA NEW GUINEA NEW ZEALAND NICARAGUA NICARAGUA  NIGERIA NORTH ATLANTIC OCEAN NORTH ATLANTIC OCEAN  NORTH PACIFIC OCEAN NORTH SEA NORTHERN ARABIAN SEA NORTHERN MARIANA ISLANDS NORWAY OCEAN OKINAWA PACIFIC OCEAN PACIFIC OCEAN  PALAU PALESTINIAN TERRITORIES PANAMA PAPUA NEW GUINEA PARAGUAY PERSIAN GULF PHILIPPINES PORTUGAL PUERTO RICO RED SEA RED SEA / INDIAN OCEAN RED SEA? REUNION RUSSIA SAMOA SAN DOMINGO SAUDI ARABIA SCOTLAND SENEGAL SEYCHELLES SIERRA LEONE SINGAPORE SLOVENIA SOLOMON ISLANDS SOLOMON ISLANDS / VANUATU SOMALIA SOUTH AFRICA SOUTH ATLANTIC OCEAN SOUTH CHINA SEA SOUTH KOREA SOUTH PACIFIC OCEAN SOUTHWEST PACIFIC OCEAN SPAIN SRI LANKA ST. MAARTIN ST. MARTIN SUDAN SUDAN? SWEDEN SYRIA Seychelles Sierra Leone St Helena TAIWAN TANZANIA TASMAN SEA THAILAND THE BALKANS TONGA TRINIDAD & TOBAGO TUNISIA TURKEY TURKS & CAICOS TUVALU UNITED ARAB EMIRATES UNITED ARAB EMIRATES (UAE) UNITED KINGDOM URUGUAY USA VANUATU VENEZUELA VIETNAM WESTERN SAMOA YEMEN YEMEN \n",
      "203\n",
      "[1, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 16, 1279, 5, 98, 1, 1, 5, 1, 3, 16, 102, 1, 1, 1, 1, 4, 1, 10, 3, 8, 2, 2, 1, 8, 6, 9, 1, 12, 2, 34, 42, 1, 1, 1, 1, 1, 7, 8, 36, 2, 1, 4, 19, 1, 1, 1, 62, 13, 22, 3, 1, 1, 1, 1, 25, 1, 4, 4, 1, 3, 1, 1, 3, 3, 24, 1, 37, 7, 1, 20, 29, 1, 12, 1, 7, 71, 1, 23, 32, 1, 2, 10, 6, 1, 1, 3, 3, 5, 7, 4, 1, 5, 13, 1, 7, 1, 2, 1, 81, 1, 3, 5, 1, 1, 3, 44, 2, 1, 1, 6, 51, 10, 125, 6, 1, 4, 4, 1, 7, 1, 1, 1, 2, 1, 6, 17, 2, 5, 1, 32, 133, 1, 4, 59, 3, 1, 1, 1, 1, 57, 4, 7, 1, 5, 8, 11, 7, 8, 6, 1, 29, 1, 6, 565, 12, 1, 8, 2, 2, 40, 13, 1, 1, 4, 1, 1, 1, 1, 1, 1, 9, 8, 1, 6, 1, 15, 3, 3, 12, 5, 1, 1, 2, 10, 3, 2116, 14, 11, 14, 1, 2, 7]\n"
     ]
    }
   ],
   "source": [
    "place = df[['Country','Area','Location']]\n",
    "\n",
    "#groups.keys() devuelve las keys de los grupos\n",
    "locations = [p for p in place.groupby('Country').groups.keys()]\n",
    "\n",
    "#print(len(place.groupby(['Location']).groups[locations[0]]))\n",
    "print(*locations)\n",
    "print(len(locations))\n",
    "print([len(place.groupby(['Country']).groups[l]) for l in locations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
